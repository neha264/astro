{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### refining 3/5 timestep classifiers\n",
    "#### rows 0-2, ~27.4 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['run', 'planet', 'initial e', 'final e', 'mean e', 'min e', 'max e',\n",
      "       'sd e', 'initial pericenter', 'final pericenter', 'mean pericenter',\n",
      "       'min pericenter', 'max pericenter', 'sd pericenter', 'initial jacobi',\n",
      "       'final jacobi', 'mean jacobi', 'min jacobi', 'max jacobi', 'sd jacobi',\n",
      "       'initial mhr1', 'final mhr1', 'mean mhr1', 'min mhr1', 'max mhr1',\n",
      "       'sd mhr1', 'initial mhr2', 'final mhr2', 'mean mhr2', 'min mhr2',\n",
      "       'max mhr2', 'sd mhr2', 'initial a1_ratio', 'final a1_ratio',\n",
      "       'mean a1_ratio', 'min a1_ratio', 'max a1_ratio', 'sd a1_ratio',\n",
      "       'initial a2_ratio', 'final a2_ratio', 'mean a2_ratio', 'min a2_ratio',\n",
      "       'max a2_ratio', 'sd a2_ratio', 'initial mass1_ratio',\n",
      "       'final mass1_ratio', 'mean mass1_ratio', 'min mass1_ratio',\n",
      "       'max mass1_ratio', 'sd mass1_ratio', 'initial mass2_ratio',\n",
      "       'final mass2_ratio', 'mean mass2_ratio', 'min mass2_ratio',\n",
      "       'max mass2_ratio', 'sd mass2_ratio', 'end time', 'fate'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "planets = pd.read_csv('3ts.csv', skipinitialspace=True)\n",
    "print(planets.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### started at ~84% accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fates = list(set(planets['fate']))\n",
    "\n",
    "types = {fates[i] : i for i in range(len(fates))}\n",
    "\n",
    "classes = []\n",
    "\n",
    "for i in range(len(planets['fate'])):\n",
    "    if planets['fate'][i] == \"remaining\":\n",
    "        classes += [0]\n",
    "    else:\n",
    "        classes += [1]\n",
    "        \n",
    "classes = np.array(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neha/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "features_train, features_test, classes_train, classes_test = train_test_split(planets, classes, test_size=0.3, random_state=7)\n",
    "\n",
    "ids_train = features_train['planet'].to_numpy()\n",
    "features_train.drop(['run', 'planet', 'fate', 'end time'], axis=1, inplace=True)\n",
    "\n",
    "cols = features_train.columns\n",
    "features_train = features_train.to_numpy()\n",
    "\n",
    "ids_test = features_test['planet'].to_numpy()\n",
    "features_test.drop(['run', 'planet', 'fate', 'end time'], axis=1, inplace=True)\n",
    "features_test = features_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = GradientBoostingClassifier(random_state=7)\n",
    "classifier.fit(features_train, classes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier is  82.66666666666667 % accurate on testing set\n"
     ]
    }
   ],
   "source": [
    "classes_predict = classifier.predict( features_test )\n",
    "print('Classifier is ', accuracy_score(classes_test, classes_predict) * 100, '% accurate on testing set' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=-1)]: Done 638 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1116 tasks      | elapsed:  2.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_features': 'sqrt', 'n_estimators': 75}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92       232\n",
      "           1       0.95      0.98      0.96       468\n",
      "\n",
      "    accuracy                           0.95       700\n",
      "   macro avg       0.95      0.94      0.94       700\n",
      "weighted avg       0.95      0.95      0.95       700\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1350 out of 1350 | elapsed:  2.4min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {#'loss': ['deviance’,‘exponential'],\n",
    "              'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "              'n_estimators': [1, 5, 10, 25, 50, 75, 100, 125, 150],\n",
    "              'max_features': ['auto','sqrt','log2']}\n",
    "              #'criterion': ['friedman_mse','mse','mae']}  \n",
    "  \n",
    "grid = GridSearchCV(GradientBoostingClassifier(), param_grid, refit = True, verbose = 1, n_jobs=-1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(features_train, classes_train)\n",
    "\n",
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "grid_predictions = grid.predict(features_train)\n",
    "  \n",
    "# print classification report \n",
    "print(classification_report(classes_train, grid_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1080 candidates, totalling 5400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   57.7s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed: 20.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.12, 'max_depth': 4, 'max_features': 'log2', 'n_estimators': 55}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       232\n",
      "           1       0.97      0.99      0.98       468\n",
      "\n",
      "    accuracy                           0.98       700\n",
      "   macro avg       0.98      0.97      0.97       700\n",
      "weighted avg       0.98      0.98      0.98       700\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 5400 out of 5400 | elapsed: 23.2min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'learning_rate': [0.02, 0.05, 0.07, 0.1, 0.12, 0.15, 0.17, 0.2],\n",
    "              'max_depth': [4, 5, 6, 7, 8],\n",
    "              'n_estimators': [50, 55, 60, 65, 70, 75, 80, 85, 90],\n",
    "              'max_features': ['auto','sqrt','log2']}  \n",
    "  \n",
    "grid = GridSearchCV(GradientBoostingClassifier(), param_grid, refit = True, verbose = 1, n_jobs=-1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(features_train, classes_train)\n",
    "\n",
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "grid_predictions = grid.predict(features_train)\n",
    "  \n",
    "# print classification report \n",
    "print(classification_report(classes_train, grid_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.12, max_depth=4, max_features='log2',\n",
       "                           n_estimators=55, random_state=7)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = GradientBoostingClassifier(learning_rate = 0.12, max_depth = 4, max_features = 'log2', n_estimators = 55, random_state=7)\n",
    "classifier.fit(features_train, classes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier is  85.66666666666667 % accurate on testing set\n"
     ]
    }
   ],
   "source": [
    "classes_predict = classifier.predict(features_test)\n",
    "print('Classifier is ', accuracy_score(classes_test, classes_predict) * 100, '% accurate on testing set' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "###### Feature importance (from old file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats=classifier.feature_importances_\n",
    "inds=np.argsort(feats)[::-1]\n",
    "\n",
    "for i in range(len(inds)):\n",
    "    print(cols[inds[i]], feats[inds[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab\n",
    "\n",
    "\n",
    "f=plt.figure(figsize=(15,7))\n",
    "\n",
    "for i in range(len(inds)):\n",
    "    plt.bar(cols[inds[i]], feats[inds[i]] * 100)\n",
    "    \n",
    "\n",
    " \n",
    "plt.ylabel('% Importance', size=16)\n",
    "plt.xlabel('Feature', size=16)\n",
    "plt.title('Feature importance', size=20)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_x = []\n",
    "unstable_x = []\n",
    "misclassified_x = []\n",
    "stable_y = []\n",
    "unstable_y = []\n",
    "misclassified_y = []\n",
    "    \n",
    "    \n",
    "f=plt.figure(figsize=(15,7))\n",
    "\n",
    "for i in range(len(features_test)):\n",
    "    if (classes_test[i] == 0 and classes_predict[i] == 0):\n",
    "        stable_x.append(features_test[i][5])\n",
    "        stable_y.append(features_test[i][39])\n",
    "    elif (classes_test[i] == 1 and classes_predict[i] == 1):\n",
    "        unstable_x.append(features_test[i][5])\n",
    "        unstable_y.append(features_test[i][39])\n",
    "    else:\n",
    "        misclassified_x.append(features_test[i][5])\n",
    "        misclassified_y.append(features_test[i][39])\n",
    "\n",
    "        \n",
    "plt.scatter(stable_x, stable_y, color = 'thistle')\n",
    "plt.scatter(misclassified_x, misclassified_y, color = 'firebrick', zorder = 2)\n",
    "plt.scatter(unstable_x, unstable_y, color = 'lightsteelblue')\n",
    "\n",
    "        \n",
    "plt.ylabel('min a2 ratio (2)')\n",
    "plt.xlabel('standard deviation e (1)')\n",
    "plt.title('sd e vs min a2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
