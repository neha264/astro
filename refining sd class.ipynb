{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### refining simplified data classifier\n",
    "#### using 3 timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets = pd.read_csv('3ts.csv', skipinitialspace=True)\n",
    "print(planets.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### started at ~84% accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fates = list(set(planets['fate']))\n",
    "\n",
    "types = {fates[i] : i for i in range(len(fates))}\n",
    "\n",
    "classes = []\n",
    "\n",
    "for i in range(len(planets['fate'])):\n",
    "    if planets['fate'][i] == \"remaining\":\n",
    "        classes += [0]\n",
    "    else:\n",
    "        classes += [1]\n",
    "        \n",
    "classes = np.array(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### playing around with features to test with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 2\n",
    "\n",
    "features_train, features_test, classes_train, classes_test = train_test_split(planets, classes, test_size=0.3, random_state=7)\n",
    "\n",
    "ru = features_test['run'].to_numpy()\n",
    "p = features_test['planet'].to_numpy()\n",
    "e = features_test['end time'].to_numpy()\n",
    "fa = features_test['fate'].to_numpy()\n",
    "\n",
    "# for graphs\n",
    "me = features_test['min e'].to_numpy()\n",
    "fa2 = features_test['final a2_ratio'].to_numpy()\n",
    "mm2 = features_test['min mass2_ratio'].to_numpy()\n",
    "\n",
    "d = ['run', 'planet', 'fate', 'end time']\n",
    "\n",
    "var = ['e','mhr1','mhr2','a1_ratio','a2_ratio','mass1_ratio','mass2_ratio','pericenter','jacobi']\n",
    "\n",
    "for v in var:\n",
    "#     d.append('initial ' + str(v))\n",
    "    d.append('final ' + str(v))\n",
    "#     d.append('mean ' + str(v))     # getting rid of mean and sd have similar accuracy results\n",
    "    d.append('min ' + str(v))\n",
    "#     d.append('max ' + str(v))\n",
    "#     d.append('sd ' + str(v))\n",
    "    \n",
    "\n",
    "ids_train = features_train['planet'].to_numpy()\n",
    "features_train.drop(d, axis=1, inplace=True)\n",
    "\n",
    "cols = features_train.columns\n",
    "features_train = features_train.to_numpy()\n",
    "\n",
    "ids_test = features_test['planet'].to_numpy()\n",
    "features_test.drop(d, axis=1, inplace=True)\n",
    "features_test = features_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 3\n",
    "\n",
    "features_train, features_test, classes_train, classes_test = train_test_split(planets, classes, test_size=0.3, random_state=7)\n",
    "\n",
    "ru = features_test['run'].to_numpy()\n",
    "p = features_test['planet'].to_numpy()\n",
    "e = features_test['end time'].to_numpy()\n",
    "fa = features_test['fate'].to_numpy()\n",
    "\n",
    "# for graphs\n",
    "me = features_test['min e'].to_numpy()\n",
    "fa2 = features_test['final a2_ratio'].to_numpy()\n",
    "mm2 = features_test['min mass2_ratio'].to_numpy()\n",
    "\n",
    "d = ['run', 'planet', 'fate', 'end time']\n",
    "\n",
    "var = ['e','mhr1','mhr2','a1_ratio','a2_ratio']\n",
    "var2 = ['mass1_ratio','mass2_ratio']\n",
    "var3 = ['pericenter','jacobi']\n",
    "\n",
    "for v in var:\n",
    "#     d.append('initial ' + str(v))\n",
    "#     d.append('final ' + str(v))\n",
    "#     d.append('mean ' + str(v))     # getting rid of mean and sd have similar accuracy results\n",
    "    d.append('min ' + str(v))\n",
    "    d.append('max ' + str(v))\n",
    "#     d.append('sd ' + str(v))\n",
    "\n",
    "\n",
    "for v in var2:\n",
    "#     d.append('initial ' + str(v))\n",
    "    d.append('final ' + str(v))\n",
    "    d.append('mean ' + str(v))     # getting rid of mean and sd have similar accuracy results\n",
    "    d.append('min ' + str(v))\n",
    "    d.append('max ' + str(v))\n",
    "    d.append('sd ' + str(v))\n",
    "\n",
    "for v in var3:\n",
    "    d.append('initial ' + str(v))\n",
    "    d.append('final ' + str(v))\n",
    "#     d.append('mean ' + str(v))\n",
    "    d.append('min ' + str(v))\n",
    "    d.append('max ' + str(v))\n",
    "    d.append('sd ' + str(v))\n",
    "    \n",
    "\n",
    "ids_train = features_train['planet'].to_numpy()\n",
    "features_train.drop(d, axis=1, inplace=True)\n",
    "\n",
    "cols = features_train.columns\n",
    "features_train = features_train.to_numpy()\n",
    "\n",
    "ids_test = features_test['planet'].to_numpy()\n",
    "features_test.drop(d, axis=1, inplace=True)\n",
    "features_test = features_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 4\n",
    "\n",
    "features_train, features_test, classes_train, classes_test = train_test_split(planets, classes, test_size=0.3, random_state=7)\n",
    "\n",
    "ru = features_test['run'].to_numpy()\n",
    "p = features_test['planet'].to_numpy()\n",
    "e = features_test['end time'].to_numpy()\n",
    "fa = features_test['fate'].to_numpy()\n",
    "\n",
    "# for graphs\n",
    "me = features_test['min e'].to_numpy()\n",
    "fa2 = features_test['final a2_ratio'].to_numpy()\n",
    "mm2 = features_test['min mass2_ratio'].to_numpy()\n",
    "\n",
    "d = ['run', 'planet', 'fate', 'end time']\n",
    "\n",
    "var = ['e','mhr1','mhr2','a1_ratio','a2_ratio']\n",
    "var2 = ['mass1_ratio','mass2_ratio']\n",
    "var3 = ['pericenter','jacobi']\n",
    "\n",
    "for v in var:\n",
    "#     d.append('initial ' + str(v))\n",
    "    d.append('final ' + str(v))\n",
    "#     d.append('mean ' + str(v))     # getting rid of mean and sd have similar accuracy results\n",
    "    d.append('min ' + str(v))\n",
    "    d.append('max ' + str(v))\n",
    "#     d.append('sd ' + str(v))\n",
    "\n",
    "\n",
    "for v in var2:\n",
    "    d.append('initial ' + str(v))\n",
    "    d.append('final ' + str(v))\n",
    "#     d.append('mean ' + str(v))     # getting rid of mean and sd have similar accuracy results\n",
    "    d.append('min ' + str(v))\n",
    "    d.append('max ' + str(v))\n",
    "    d.append('sd ' + str(v))\n",
    "\n",
    "for v in var3:\n",
    "    d.append('initial ' + str(v))\n",
    "#     d.append('final ' + str(v))\n",
    "    d.append('mean ' + str(v))\n",
    "    d.append('min ' + str(v))\n",
    "    d.append('max ' + str(v))\n",
    "    d.append('sd ' + str(v))\n",
    "    \n",
    "\n",
    "ids_train = features_train['planet'].to_numpy()\n",
    "features_train.drop(d, axis=1, inplace=True)\n",
    "\n",
    "cols = features_train.columns\n",
    "features_train = features_train.to_numpy()\n",
    "\n",
    "ids_test = features_test['planet'].to_numpy()\n",
    "features_test.drop(d, axis=1, inplace=True)\n",
    "features_test = features_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### testing, refine hyperparameters (grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original, no parameters\n",
    "\n",
    "classifier = GradientBoostingClassifier(random_state=7)\n",
    "classifier.fit(features_train, classes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'learning_rate': [0.05, 0.07, 0.1, 0.12, 0.15],\n",
    "              'max_depth': [4],\n",
    "              'n_estimators': [70, 75, 77, 80, 82]\n",
    "              'max_features': ['auto','sqrt','log2']}  \n",
    "  \n",
    "grid = GridSearchCV(GradientBoostingClassifier(), param_grid, refit = True, n_jobs=-1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(features_train, classes_train)\n",
    "\n",
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "grid_predictions = grid.predict(features_train)\n",
    "  \n",
    "# print classification report \n",
    "print(classification_report(classes_train, grid_predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rounds of further refining of hyperparameters (documentation in msef doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GradientBoostingClassifier(learning_rate = 0.05, max_depth = 4, max_features = 'auto', n_estimators = 75, random_state=7)\n",
    "classifier.fit(features_train, classes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GradientBoostingClassifier(learning_rate = 0.1, max_depth = 4, max_features = 'log2', n_estimators = 75, random_state=7)\n",
    "classifier.fit(features_train, classes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GradientBoostingClassifier(learning_rate = 0.12, max_depth = 4, max_features = 'log2', n_estimators = 80, random_state=7)\n",
    "classifier.fit(features_train, classes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GradientBoostingClassifier(learning_rate = 0.15, max_depth = 4, max_features = 'log2', n_estimators = 83, random_state=7)\n",
    "classifier.fit(features_train, classes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_predict = classifier.predict(features_test)\n",
    "print('Classifier is ', accuracy_score(classes_test, classes_predict) * 100, '% accurate on testing set' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "###### feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats=classifier.feature_importances_\n",
    "inds=np.argsort(feats)[::-1]\n",
    "\n",
    "for i in range(len(inds)):\n",
    "    print(cols[inds[i]], feats[inds[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab\n",
    "\n",
    "\n",
    "f=plt.figure(figsize=(15,7))\n",
    "\n",
    "for i in range(len(inds)):\n",
    "    plt.bar(cols[inds[i]], feats[inds[i]] * 100)\n",
    "    \n",
    "\n",
    " \n",
    "plt.ylabel('% Importance', size=16)\n",
    "plt.xlabel('Feature', size=16)\n",
    "plt.title('Feature importance', size=20)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### playing around with important features - correctly classified vs misclassified planets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Maybe revisit the data generation step to try to find the two dynamically closest planets instead of the inner and outer planets in your data set? \n",
    "2. Begin to explore the misclassified objects:\n",
    "    - What are the instability times for misclassified planets?\n",
    "    - Does the evolution of misclassified planets look different (e.g., does something like a vs. time or e vs. time give us any insight?)\n",
    "    - (For instance, I might guess that most of the misclassified planets are truly unstable but classified as stable and have long instability times)\n",
    "3. Look at the probabilities of class membership (how sure are we that planets are stable or unstable)\n",
    "    - You can use the classifier method predict_proba (https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier.predict_proba)\n",
    "    - Do the misclassified objects have high or low probabilities?\n",
    "    - How many of the correctly classified objects have high probability? (more than 90%? 95%? 99.9%?)\n",
    "    - What is probability as a function of instability time for the unstable planets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_x = []\n",
    "unstable_x = []\n",
    "misclassified_x = []\n",
    "stable_y = []\n",
    "unstable_y = []\n",
    "misclassified_y = []\n",
    "    \n",
    "    \n",
    "f=plt.figure(figsize=(15,7))\n",
    "\n",
    "for i in range(len(features_test)):\n",
    "    if (classes_test[i] == 0 and classes_predict[i] == 0):\n",
    "        stable_x.append(features_test[i][18])\n",
    "        stable_y.append(features_test[i][26])\n",
    "    elif (classes_test[i] == 1 and classes_predict[i] == 1):\n",
    "        unstable_x.append(features_test[i][18])\n",
    "        unstable_y.append(features_test[i][26])\n",
    "    else:\n",
    "        misclassified_x.append(features_test[i][18])\n",
    "        misclassified_y.append(features_test[i][26])\n",
    "\n",
    "        \n",
    "plt.scatter(stable_x, stable_y, color = 'thistle')\n",
    "plt.scatter(misclassified_x, misclassified_y, color = 'firebrick', zorder = 2)\n",
    "plt.scatter(unstable_x, unstable_y, color = 'lightsteelblue')\n",
    "\n",
    "        \n",
    "plt.ylabel('max mass2 ratio (2)')\n",
    "plt.xlabel('initial a2 ratio (1)')\n",
    "plt.title('initial a2 vs mass2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=plt.figure(figsize=(15,7))\n",
    "\n",
    "for i in range(0,len(features_test)):\n",
    "    if (classes_test[i] != classes_predict[i]):\n",
    "        if (classes_test[i] == 0):    # is actually stable\n",
    "            plt.scatter(features_test[i][18], features_test[i][26], color = 'mediumpurple', zorder = 3)\n",
    "        else:                         # is actually unstable\n",
    "            plt.scatter(features_test[i][18], features_test[i][26], color = 'cornflowerblue', zorder = 3)\n",
    "    else:                             # correct\n",
    "        plt.scatter(features_test[i][18], features_test[i][26], color = 'lightgray', alpha=0.5)\n",
    "        \n",
    "plt.xlabel('initial a2 ratio (1)')\n",
    "plt.ylabel('max mass2 ratio (2)')\n",
    "plt.title('initial a2 vs mass2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=plt.figure(figsize=(15,7))\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(0,len(features_test)):\n",
    "    x.append(features_test[i][18])\n",
    "    y.append(fa2[i])\n",
    "    \n",
    "    if (classes_test[i] != classes_predict[i]):\n",
    "        if (classes_test[i] == 0):    # is actually stable\n",
    "            plt.scatter(features_test[i][18], fa2[i], color = 'mediumpurple', zorder = 5)\n",
    "        else:  # is actually unstable\n",
    "            plt.scatter(features_test[i][18], fa2[i], color = 'cornflowerblue', zorder = 5)\n",
    "    else:\n",
    "        plt.scatter(features_test[i][18], fa2[i], color = 'lightgray', alpha=0.7)\n",
    "        \n",
    "        \n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color='black', alpha = 0.5)\n",
    "\n",
    "\n",
    "plt.xlabel('initial a2 (1)')\n",
    "plt.ylabel('final a2')\n",
    "plt.title('initial vs final a2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=plt.figure(figsize=(15,7))\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(0,len(features_test)):\n",
    "    x.append(features_test[i][26])\n",
    "    y.append(mm2[i])\n",
    "    \n",
    "    if (classes_test[i] != classes_predict[i]):\n",
    "        if (classes_test[i] == 0):    # is actually stable\n",
    "            plt.scatter(features_test[i][26], mm2[i], color = 'mediumpurple', zorder = 5)\n",
    "        else:                         # is actually unstable\n",
    "            plt.scatter(features_test[i][26], mm2[i], color = 'cornflowerblue', zorder = 5)\n",
    "    else:\n",
    "        plt.scatter(features_test[i][26], mm2[i], color = 'lightgray', alpha=0.7)\n",
    "\n",
    "        \n",
    "# plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color='black', alpha = 0.5)\n",
    "\n",
    "        \n",
    "plt.xlabel('max mass2 ratio (2)')\n",
    "plt.ylabel('min mass2 ratio')\n",
    "plt.title('min vs max mass2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=plt.figure(figsize=(15,7))\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(0,len(features_test)):\n",
    "    x.append(features_test[i][1])\n",
    "    y.append(me[i])\n",
    "    \n",
    "    if (classes_test[i] != classes_predict[i]):\n",
    "        if (classes_test[i] == 0):    # is actually stable\n",
    "            plt.scatter(features_test[i][1], me[i], color = 'mediumpurple', zorder = 5)\n",
    "        else:  # is actually unstable\n",
    "            plt.scatter(features_test[i][1], me[i], color = 'cornflowerblue', zorder = 5)\n",
    "    else:\n",
    "        plt.scatter(features_test[i][1], me[i], color = 'lightgray', alpha=0.7)\n",
    "       \n",
    "\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color='black', alpha = 0.5)\n",
    "\n",
    "        \n",
    "# plt.ylim(-0.25, 1)        \n",
    "plt.xlabel('max e (3)')\n",
    "plt.ylabel('min e')\n",
    "plt.title('min vs max e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### probability - stable/unstable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of probabilities\n",
    "\n",
    "r = classifier.predict_proba(features_test) \n",
    "n = 0\n",
    "n90 = 0\n",
    "n95 = 0\n",
    "n99 = 0\n",
    "\n",
    "for i in range(0,len(r)):\n",
    "    if (classes_test[i] == classes_predict[i]):\n",
    "        n += 1\n",
    "        if (classes_test[i] == 0):\n",
    "            if ((r[i][0] * 100) > 90):\n",
    "                n90 += 1\n",
    "                if ((r[i][0] * 100) > 95):\n",
    "                    n95 += 1\n",
    "                    if ((r[i][0] * 100) > 99):\n",
    "                            n99 += 1\n",
    "            \n",
    "        else:\n",
    "            if ((r[i][1] * 100) > 90):\n",
    "                n90 += 1\n",
    "                if ((r[i][1] * 100) > 95):\n",
    "                    n95 += 1\n",
    "                    if ((r[i][1] * 100) > 99):\n",
    "                        n99 += 1\n",
    "\n",
    "print('Sample size: ' + str(len(r)))\n",
    "print('\\nNumber of correctly classified planets: ' + str(n))\n",
    "print('\\nCorrectly classified planets with probability >90%: ' + str(n90))\n",
    "print('\\nCorrectly classified planets with probability >95%: ' + str(n95))\n",
    "print('\\nCorrectly classified planets with probability >99%: ' + str(n99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram\n",
    "\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "c = []\n",
    "w = []\n",
    "\n",
    "\n",
    "# correct\n",
    "inds = []\n",
    "\n",
    "for i in range(0,len(classes_test)):\n",
    "    if (classes_test[i] == classes_predict[i]):   # 0 = stable, 1 = unstable\n",
    "        inds.append(i)\n",
    "\n",
    "r = classifier.predict_proba(features_test)\n",
    "\n",
    "for i in range(0,len(r)):\n",
    "    if (classes_test[i] == classes_predict[i]):\n",
    "        if (classes_test[i] == 0):\n",
    "            c.append(r[i][0]*100)\n",
    "        else:\n",
    "            c.append(r[i][1]*100)\n",
    "            \n",
    "            \n",
    "# wrong\n",
    "inds2 = []\n",
    "\n",
    "r2 = classifier.predict_proba(features_test)   # col 1 = stable\n",
    "\n",
    "for i in range(0,len(classes_test)):\n",
    "    if (classes_test[i] != classes_predict[i]):   # 0 = stable, 1 = unstable\n",
    "        inds2.append(i)\n",
    "\n",
    "for i in range(0,len(r2)):\n",
    "    if (classes_test[i] != classes_predict[i]):\n",
    "        if (classes_test[i] == 0):\n",
    "            w.append(r2[i][1]*100)\n",
    "        else:\n",
    "            w.append(r2[i][0]*100)\n",
    "            \n",
    "            \n",
    "plt.subplot(1, 2, 1)\n",
    "N, bins, patches = plt.hist(c, bins = 8)\n",
    "fracs = N / N.max()\n",
    "norm = colors.Normalize(fracs.min(), fracs.max())\n",
    "\n",
    "for thisfrac, thispatch in zip(fracs, patches):\n",
    "    color = plt.cm.viridis(norm(thisfrac))\n",
    "    thispatch.set_facecolor(color)\n",
    "\n",
    "plt.xlabel('Probabilities distribution for \\ncorrectly classified planets (%)')\n",
    "plt.ylabel('Frequency')\n",
    "# plt.ylim(0,200)\n",
    "# plt.xlim(50,100)\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "N, bins, patches = plt.hist(w, bins = 5)\n",
    "fracs = N / N.max()\n",
    "norm = colors.Normalize(fracs.min(), fracs.max())\n",
    "\n",
    "for thisfrac, thispatch in zip(fracs, patches):\n",
    "    color = plt.cm.viridis(norm(thisfrac))\n",
    "    thispatch.set_facecolor(color)\n",
    "\n",
    "plt.xlabel('Probability distribution for \\nmisclassified planets (%)') \n",
    "# plt.ylim(0,200)\n",
    "# plt.xlim(50,100)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# certainity/probability for misclassified ones, average percentage\n",
    "\n",
    "r = classifier.predict_proba(features_test)   # col 0 = stable, 1 = unstable\n",
    "m = []\n",
    "\n",
    "print('Misclassified objects - unstable/stable probabilities: \\n')\n",
    "for i in range(0,len(r)):\n",
    "    if (classes_test[i] != classes_predict[i]):\n",
    "        print('Stable: ' + str(r[i][0]) + '. Unstable: ' + str(r[i][1]))\n",
    "        if (classes_test[i] == 0):\n",
    "            # print('Predicted: unstable. Actual: stable \\n')\n",
    "            m.append(r[i][0])\n",
    "        else:\n",
    "            # print('Predicted: stable. Actual: unstable \\n')\n",
    "            m.append(r[i][1])\n",
    "            \n",
    "print('\\nAverage probability for misclassified objects: ' + str(np.mean(m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# certainity/probability for misclassified ones, average percentage\n",
    "\n",
    "r = classifier.predict_proba(features_test)   # col 0 = stable, 1 = unstable\n",
    "m = []\n",
    "acs = []\n",
    "acu = []\n",
    "\n",
    "cu = 0    # count actually unstable//actually stable\n",
    "cs = 0\n",
    "\n",
    "print('Misclassified planets: \\n')\n",
    "\n",
    "for i in range(0,len(r)):\n",
    "    if (classes_test[i] != classes_predict[i]):\n",
    "#         print('Run ' + str(ru[i]) + ', Planet ' + str(p[i]))\n",
    "        if (classes_predict[i] == 0):\n",
    "            print('Probability - ' + str(r[i][0] * 100) + '\\nPredicted stable, actually unstable')\n",
    "            m.append(r[i][0] * 100)\n",
    "            acu.append(r[i][0] * 100)\n",
    "            cu += 1\n",
    "        else:\n",
    "            print('Probability - ' + str(r[i][1] * 100) + '\\nPredicted unstable, actually stable')\n",
    "            m.append(r[i][1] * 100)\n",
    "            acs.append(r[i][1] * 100)\n",
    "            cs += 1\n",
    "            \n",
    "        print('Instability Time: ' + str(e[i]) + '\\n')\n",
    "        \n",
    "print('\\nAverage probability for misclassified planets: ' + str(np.mean(m)))\n",
    "print('\\nAverage probability for planets predicted stable, actually unstable: ' + str(np.mean(acu)))\n",
    "print('\\nAverage probability for planets predicted unstable, actually stable: ' + str(np.mean(acs)))\n",
    "\n",
    "print('\\nNumber of misclassified planets predicted unstable, actually stable: ' + str(cs))\n",
    "print('Number of misclassified planets predicted stable, actually unstable: ' + str(cu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# certainity/probability for correctly classified planets, average percentage\n",
    "\n",
    "r = classifier.predict_proba(features_test) \n",
    "m = []\n",
    "s = []\n",
    "u = []\n",
    "\n",
    "print('Probabilities for correctly classified planets: \\n')\n",
    "for i in range(0,len(r)):\n",
    "    if (classes_test[i] == classes_predict[i]):\n",
    "        if (classes_test[i] == 0):\n",
    "            print(str(r[i][0] * 100) + ' - stable')\n",
    "            m.append(r[i][0] * 100)\n",
    "            s.append(r[i][0] * 100)\n",
    "        else:\n",
    "            print(str(r[i][1] * 100) + ' - unstable')\n",
    "            m.append(r[i][1] * 100)\n",
    "            u.append(r[i][1] * 100)\n",
    "            \n",
    "print('\\nAverage probability for correctly classified objects: ' + str(np.mean(m)))\n",
    "print('\\nAverage probability for planets correctly classified as stable: ' + str(np.mean(s)))\n",
    "print('\\nAverage probability for planets correctly classified as unstable: ' + str(np.mean(u)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = []\n",
    "inst = []\n",
    "\n",
    "\n",
    "f=plt.figure(figsize=(15,7))\n",
    "\n",
    "for i in range(0,len(r)):\n",
    "    if (classes_test[i] == 1):\n",
    "        prob.append(r[i][1] * 100)\n",
    "        inst.append(np.log10(e[i]))\n",
    "        \n",
    "        if (classes_predict[i] == 1):\n",
    "            plt.scatter(np.log10(e[i]), r[i][1] * 100, color = 'seagreen', alpha = 0.8)\n",
    "        elif (classes_predict[i] == 0):\n",
    "            plt.scatter(np.log10(e[i]), r[i][1] * 100, color = 'firebrick', alpha = 0.8)\n",
    "\n",
    "            \n",
    "plt.plot(np.unique(inst), np.poly1d(np.polyfit(inst, prob, 1))(np.unique(inst)), color='black')\n",
    "            \n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Log10(Instability Time)')\n",
    "plt.title('Unstable planets - probability vs instability time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = []\n",
    "inst = []\n",
    "\n",
    "    \n",
    "f=plt.figure(figsize=(15,7))\n",
    "\n",
    "for i in range(0,len(classes_test)):\n",
    "    if (classes_test[i] == 1):\n",
    "        prob.append(r[i][1] * 100)\n",
    "        inst.append(e[i])\n",
    "            \n",
    "            \n",
    "plt.scatter(prob, inst, marker = 'o')\n",
    "\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Instability Time')\n",
    "plt.title('Unstable planets - probability vs instability time')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
